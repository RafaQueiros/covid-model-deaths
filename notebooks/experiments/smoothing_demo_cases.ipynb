{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import warnings\n",
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "from db_queries import get_location_metadata, get_population\n",
    "\n",
    "from covid_model_deaths.preprocessing import expanding_moving_average_by_location\n",
    "\n",
    "pd.options.display.max_rows = 99\n",
    "pd.options.display.max_columns = 99\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "MODEL_INPUTS_VERSION = '2020_05_03.24'\n",
    "SNAPSHOT_VERSION = '2020_05_03.02'\n",
    "# US_MODEL = '2020_05_03_US'\n",
    "# GLOBAL_MODEL = '2020_05_03_Europe'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define smoother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_moving_average(data: pd.DataFrame, smoooth_var: str,\n",
    "                       rate_threshold: float, n_smooths: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"Smooths over the log age specific death rate.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data\n",
    "        The data with the age specific death rate to smooth over.\n",
    "    rate_threshold\n",
    "        The minimum age specific death rate.  Values produced in the\n",
    "        averaging will be pinned to this.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        The same data with the log asdr replaced with its average and a new\n",
    "        column with the original observed asdr.\n",
    "\n",
    "    \"\"\"\n",
    "    required_columns = ['location_id', 'Date', 'Days', smoooth_var]\n",
    "    assert set(required_columns).issubset(data.columns)\n",
    "    data[f'Observed {smoooth_var}'] = data[smoooth_var]\n",
    "    # smooth n times\n",
    "    for i in range(n_smooths):\n",
    "        moving_average = expanding_moving_average_by_location(data, smoooth_var)\n",
    "        # noinspection PyTypeChecker\n",
    "        moving_average[moving_average < rate_threshold] = rate_threshold\n",
    "        data = data.set_index(['location_id', 'Date'])\n",
    "        data = (pd.concat([data.drop(columns=smoooth_var), moving_average], axis=1)\n",
    "                .fillna(method='pad')\n",
    "                .reset_index())\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data and smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_df = get_location_metadata(location_set_version_id=655, location_set_id=111)\n",
    "loc_df = loc_df.loc[((loc_df['most_detailed'] == 1) & (loc_df['parent_id'] != 570)) | (loc_df['location_id'] == 570)]\n",
    "\n",
    "wa_pop_df = get_population(decomp_step='step4', gbd_round_id=6,\n",
    "                        location_id=570, year_id=2019,\n",
    "                        age_group_id=22, sex_id=3)\n",
    "\n",
    "\n",
    "# get WA from JHU snapshot\n",
    "data_dir = f'/ihme/covid-19/snapshot-data/{SNAPSHOT_VERSION}/johns_hopkins_repo/COVID-19-master/csse_covid_19_data/csse_covid_19_daily_reports'\n",
    "date_files = os.listdir(data_dir)\n",
    "date_files = sorted([i for i in date_files if i.endswith('.csv')])\n",
    "wa_dfs = []\n",
    "for date_file in date_files:\n",
    "    wa_df = pd.read_csv(f'{data_dir}/{date_file}')\n",
    "    wa_df = wa_df.rename(index=str, columns={'Province_State':'Province/State',\n",
    "                                       'Country_Region':'Country/Region'})\n",
    "    wa_df = wa_df.loc[(wa_df['Province/State'] == 'Washington') & (wa_df['Country/Region'] == 'US')]\n",
    "    wa_df['Date'] = pd.to_datetime(date_file[:-4])\n",
    "    wa_df = wa_df.groupby(['Province/State', 'Country/Region', 'Date'], as_index=False)['Confirmed'].sum()\n",
    "    wa_dfs.append(wa_df)\n",
    "wa_df = pd.concat(wa_dfs).reset_index(drop=True)\n",
    "wa_df['population'] = wa_pop_df['population'].item()\n",
    "wa_df['location_id'] = wa_pop_df['location_id'].item()\n",
    "wa_df['Confirmed case rate'] = wa_df['Confirmed'] / wa_df['population']\n",
    "wa_df = wa_df[['location_id', 'Date', 'Confirmed', 'Confirmed case rate', 'population']]\n",
    "\n",
    "# get rest of data\n",
    "df = pd.read_csv(f'/ihme/covid-19/model-inputs/{MODEL_INPUTS_VERSION}/full_data.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.loc[~df['Confirmed'].isnull()]\n",
    "df = df[['location_id', 'Date', 'Confirmed', 'Confirmed case rate', 'population']].append(wa_df).reset_index(drop=True)\n",
    "df['ln(case rate)'] = np.log(df['Confirmed case rate'])\n",
    "df.loc[df['Confirmed'] == 0, 'ln(case rate)'] = np.log(0.1 / df['population'])\n",
    "df['day0'] = df.groupby('location_id', as_index=False)['Date'].transform(min)\n",
    "df['Days'] = df.apply(lambda x: (x['Date'] - x['day0']).days, axis=1)\n",
    "df = df[['location_id', 'Date', 'Days', 'ln(case rate)', 'population']]\n",
    "df = loc_df[['location_id', 'location_name']].merge(df)\n",
    "locations = df['location_id'].unique().tolist()\n",
    "\n",
    "smooth_dfs = []\n",
    "for n_smooths in range(11):\n",
    "    if n_smooths == 0:\n",
    "        smooth_dfs.append(df.copy())\n",
    "    else:\n",
    "        smooth_dfs.append(add_moving_average(df.copy(), 'ln(case rate)', -np.inf, n_smooths))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save cases (move this into production pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_df = smooth_dfs[10]\n",
    "# us_locs = loc_df.loc[loc_df['path_to_top_parent'].str.startswith('102,'), 'location_id'].to_list()\n",
    "# g_locs = loc_df.loc[~loc_df['path_to_top_parent'].str.startswith('102,'), 'location_id'].to_list()\n",
    "# save_df.loc[save_df['location_id'].isin(us_locs)].to_csv(f'/ihme/covid-19/deaths/prod/{US_MODEL}/smoothed_cases.csv', \n",
    "#                                                          index=False)\n",
    "# save_df.loc[save_df['location_id'].isin(g_locs)].to_csv(f'/ihme/covid-19/deaths/prod/{GLOBAL_MODEL}/smoothed_cases.csv', \n",
    "#                                                         index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "with PdfPages('/ihme/homes/rmbarber/covid-19/smoothing_effect_cases_05_03_firstdiff_onestep.pdf') as pdf:\n",
    "    for location in locations:\n",
    "        # set up figure\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(16.5, 8.5))\n",
    "        \n",
    "        # plot the data\n",
    "        for n_smooths, smooth_df in enumerate(smooth_dfs):\n",
    "            plot_df = smooth_df.loc[smooth_df['location_id'] == location].reset_index(drop=True)\n",
    "            location_name = plot_df['location_name'][0]\n",
    "            if n_smooths == 0:\n",
    "                metadata = dict(color='black', linewidth=3, alpha=0.5, label=n_smooths)\n",
    "            else:\n",
    "                metadata = dict(linewidth=3, alpha=0.75, label=n_smooths)\n",
    "            if n_smooths == 0:\n",
    "                ax[0].scatter(plot_df['Date'], \n",
    "                              np.exp(plot_df['ln(case rate)']) * plot_df['population'],\n",
    "                              c='black', s=75, alpha=0.5)\n",
    "                ax[1].scatter(plot_df['Date'][1:], \n",
    "                              (np.exp(plot_df['ln(case rate)']) * plot_df['population']).values[1:] - \\\n",
    "                              (np.exp(plot_df['ln(case rate)']) * plot_df['population']).values[:-1],\n",
    "                              c='black', s=75, alpha=0.5)\n",
    "            ax[0].plot(plot_df['Date'], \n",
    "                       np.exp(plot_df['ln(case rate)']) * plot_df['population'],\n",
    "                       **metadata)\n",
    "            ax[1].plot(plot_df['Date'][1:], \n",
    "                       (np.exp(plot_df['ln(case rate)']) * plot_df['population']).values[1:] - \\\n",
    "                       (np.exp(plot_df['ln(case rate)']) * plot_df['population']).values[:-1],\n",
    "                       **metadata)\n",
    "            \n",
    "        # major ticks every week, minor ticks every day\n",
    "        major_ticks = np.arange(0, 70, 7)\n",
    "        major_ticks = np.array([plot_df['Date'].min() + timedelta(days=int(t)) for t in major_ticks])\n",
    "        major_ticks = major_ticks[major_ticks <= plot_df['Date'].max()]\n",
    "        minor_ticks = np.arange(0, 70)\n",
    "        minor_ticks = np.array([plot_df['Date'].min() + timedelta(days=int(t)) for t in minor_ticks])\n",
    "        minor_ticks = minor_ticks[minor_ticks <= plot_df['Date'].max()]\n",
    "        ax[0].set_xticks(major_ticks)\n",
    "        ax[0].set_xticks(minor_ticks, minor=True)\n",
    "        ax[0].grid(axis='y', which='major', color='darkgrey', alpha=0.25, linewidth=2)\n",
    "        ax[0].grid(axis='x', which='major', color='darkgrey', alpha=0.25, linewidth=2)\n",
    "        ax[0].grid(axis='x', which='minor', color='darkgrey', alpha=0.25, linewidth=0.2)\n",
    "        ax[1].set_xticks(major_ticks)\n",
    "        ax[1].set_xticks(minor_ticks, minor=True)\n",
    "        ax[1].grid(axis='y', which='major', color='darkgrey', alpha=0.25, linewidth=2)\n",
    "        ax[1].grid(axis='x', which='major', color='darkgrey', alpha=0.25, linewidth=2)\n",
    "        ax[1].grid(axis='x', which='minor', color='darkgrey', alpha=0.25, linewidth=0.2)\n",
    "        \n",
    "        # other settings\n",
    "        \n",
    "        ax[0].set_ylabel('Cumulative reported cases')\n",
    "        ax[0].axhline(0, color='darkgrey', linestyle='--', linewidth=3)\n",
    "        ax[0].tick_params(axis='x', rotation=60)\n",
    "        ax[1].set_ylabel('Daily reported cases')\n",
    "        ax[1].axhline(0, color='darkgrey', linestyle='--', linewidth=3)\n",
    "        ax[1].tick_params(axis='x', rotation=60) \n",
    "        \n",
    "        # legend\n",
    "        ax[0].legend(loc=2)\n",
    "        \n",
    "        # title\n",
    "        plt.suptitle(location_name, y=1.0025)\n",
    "        \n",
    "        # save\n",
    "        plt.tight_layout()\n",
    "        pdf.savefig()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
