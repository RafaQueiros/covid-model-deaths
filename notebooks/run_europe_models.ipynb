{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "from db_queries import get_location_metadata\n",
    "import pandas as pd\n",
    "\n",
    "from covid_model_deaths import runner\n",
    "from covid_model_deaths.deaths_io import InputsContext, MEASURES, Checkpoint\n",
    "from covid_model_deaths.globals import COLUMNS\n",
    "\n",
    "pd.options.display.max_rows = 99\n",
    "pd.options.display.max_columns = 99\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "RUN_TYPE = 'prod'\n",
    "DATA_VERSION = 'best'\n",
    "DATESTAMP_LABEL = '2020_05_03_Europe'\n",
    "\n",
    "PEAK_FILE = '/ihme/covid-19/deaths/mobility_inputs/2020_04_20/peak_locs_april20_.csv'\n",
    "PEAK_DURATION_FILE = None\n",
    "R0_FILE = None\n",
    "LOCATION_SET_VERSION = 655\n",
    "r0_locs = []\n",
    "\n",
    "CODE_DIR = os.path.abspath('../src/covid_model_deaths')\n",
    "OUTPUT_DIR = f'/ihme/covid-19/deaths/{RUN_TYPE}/{DATESTAMP_LABEL}'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)\n",
    "inputs = InputsContext(f'/ihme/covid-19/model-inputs/{DATA_VERSION}')\n",
    "checkpoint = Checkpoint(OUTPUT_DIR)\n",
    "\n",
    "print(f'Writing to {OUTPUT_DIR}')\n",
    "print(CODE_DIR)\n",
    "print(checkpoint)\n",
    "\n",
    "raw_draw_path = f'{OUTPUT_DIR}/euro_data.csv'\n",
    "average_draw_path = f'{OUTPUT_DIR}/past_avg_euro_data.csv'\n",
    "yesterday_draw_path = '/ihme/covid-19/deaths/prod/2020_05_01_Europe_newmod/euro_data.csv'\n",
    "before_yesterday_draw_path = '/ihme/covid-19/deaths/prod/2020_04_29_Europe/euro_data.csv'\n",
    "\n",
    "\n",
    "def filter_data(data: pd.DataFrame, kind='full') -> pd.DataFrame:\n",
    "    # manually adjust Iceland spike (0 deaths to 5 deaths to 0 deaths in March...)\n",
    "    iceland = data['Country/Region'] == 'Iceland'\n",
    "    iceland_spike = iceland & (data['Date'] == pd.Timestamp('2020-03-15'))\n",
    "    if kind == 'full':\n",
    "        data.loc[iceland_spike, ['Deaths', 'Death rate']] = 0\n",
    "    elif kind == 'deaths':\n",
    "        data = data.loc[~iceland_spike]\n",
    "        min_iceland_date = data.loc[iceland, 'Date'].min()\n",
    "        data.loc[iceland, 'Days'] = (data.loc[iceland, 'Date'] - min_iceland_date).dt.days\n",
    "        \n",
    "    # dropping data from May 1 for Mississippi for Lazio and Mississippi\n",
    "    mississippi_lazio = data['location_id'].isin([547, 35506])\n",
    "    mississippi_lazio_spike = mississippi_lazio & (data['Date'] == pd.Timestamp('2020-05-01'))\n",
    "    data = data.loc[~mississippi_lazio_spike].reset_index(drop=True)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def get_locations(location_set_version_id):\n",
    "    # get locaton_ids\n",
    "    loc_df = get_location_metadata(location_set_id=111,\n",
    "                                   location_set_version_id=location_set_version_id)\n",
    "\n",
    "    # Drop any locations in the US and keep only most detailed for modeling\n",
    "    most_detailed = loc_df['most_detailed'] == 1\n",
    "    non_us = ~loc_df['path_to_top_parent'].str.startswith('102,')\n",
    "    # Bad aggregates that made it in the hierarchy\n",
    "    good_ids = ~loc_df['location_id'].isin([53474, 53451, 53452]) \n",
    "    keep_columns = ['location_id', 'location_ascii_name', 'parent_id', 'level', 'most_detailed']\n",
    "\n",
    "    euro_df = loc_df.loc[most_detailed & non_us & good_ids, keep_columns]\n",
    "    euro_df = euro_df.rename(columns={'location_ascii_name':'Location'})\n",
    "\n",
    "    # Add parents\n",
    "    loc_df = loc_df[['location_id', 'location_ascii_name']]\n",
    "    loc_df = loc_df.rename(columns={'location_id':'parent_id',\n",
    "                                    'location_ascii_name':'Country/Region'})\n",
    "    euro_df = euro_df.merge(loc_df)\n",
    "\n",
    "    euro_df = euro_df.loc[:, ['location_id', 'Location', 'Country/Region', 'level']]\n",
    "    return euro_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_df = get_locations(LOCATION_SET_VERSION)\n",
    "input_full_df = filter_data(inputs.load(MEASURES.full_data))\n",
    "input_death_df = filter_data(inputs.load(MEASURES.deaths), kind='deaths')\n",
    "input_age_pop_df = inputs.load(MEASURES.age_pop)\n",
    "input_age_death_df = inputs.load(MEASURES.age_death)\n",
    "\n",
    "# Save pops for Bobby.\n",
    "pop_df = input_age_pop_df.merge(loc_df).reset_index(drop=True)\n",
    "pop_df[['location_id', 'Location', 'age_group', 'population']].to_csv(f'{OUTPUT_DIR}/pops.csv', index=False)\n",
    "\n",
    "checkpoint.write('location', loc_df)\n",
    "checkpoint.write('full_data', input_full_df)\n",
    "checkpoint.write('deaths', input_death_df)\n",
    "checkpoint.write('age_pop', input_age_pop_df)\n",
    "checkpoint.write('age_death', input_age_death_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## prepare data for case-to-death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "full_df = checkpoint.load('full_data')\n",
    "death_df = checkpoint.load('deaths')\n",
    "age_pop_df = checkpoint.load('age_pop')\n",
    "age_death_df = checkpoint.load('age_death')\n",
    "\n",
    "backcast_location_ids = runner.get_backcast_location_ids(full_df, most_detailed=False)\n",
    "cases_and_backcast_deaths_df = runner.make_cases_and_backcast_deaths(full_df, death_df, age_pop_df, age_death_df, backcast_location_ids, subnat=False)\n",
    "\n",
    "cases_and_backcast_deaths_df.to_csv(f'{OUTPUT_DIR}/backcast_for_case_to_death.csv', index=False)\n",
    "checkpoint.write('cases_and_backcast_deaths', cases_and_backcast_deaths_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute death thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cases_and_backcast_deaths_df = checkpoint.load('cases_and_backcast_deaths')\n",
    "loc_df = checkpoint.load('location')\n",
    "threshold_dates = runner.impute_death_threshold(cases_and_backcast_deaths_df,\n",
    "                                                loc_df)\n",
    "threshold_dates.to_csv(f'{OUTPUT_DIR}/threshold_dates.csv', index=False)\n",
    "checkpoint.write('threshold_dates', threshold_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make last day data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = checkpoint.load('full_data')\n",
    "threshold_dates = checkpoint.load('threshold_dates')\n",
    "\n",
    "date_mean_df = runner.make_date_mean_df(threshold_dates)\n",
    "last_day_df = runner.make_last_day_df(full_df,date_mean_df)\n",
    "last_day_df.to_csv(f'{OUTPUT_DIR}/last_day.csv', index=False)\n",
    "\n",
    "checkpoint.write('date_mean', date_mean_df)\n",
    "checkpoint.write('last_day', last_day_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get leading indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = checkpoint.load('full_data')\n",
    "loc_df = checkpoint.load('location')\n",
    "\n",
    "dcr_df, dhr_df, leading_indicator_df = runner.make_leading_indicator(\n",
    "    full_df.loc[full_df[COLUMNS.location_id].isin(loc_df[COLUMNS.location_id].to_list())]\n",
    ")\n",
    "dcr_df.to_csv(f'{OUTPUT_DIR}/lagged_death_to_case_ratios.csv', index=False)\n",
    "dhr_df.to_csv(f'{OUTPUT_DIR}/lagged_death_to_hosp_ratios.csv', index=False)\n",
    "leading_indicator_df.to_csv(f'{OUTPUT_DIR}/leading_indicator.csv', index=False)\n",
    "leading_indicator_df = leading_indicator_df[[COLUMNS.location_id, COLUMNS.date, COLUMNS.ln_age_death_rate]]\n",
    "leading_indicator_df = leading_indicator_df.loc[~leading_indicator_df[COLUMNS.ln_age_death_rate].isnull()]\n",
    "\n",
    "checkpoint.write('leading_indicator', leading_indicator_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store model data and covariate data, submit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = checkpoint.load('full_data')\n",
    "death_df = checkpoint.load('deaths')\n",
    "age_pop_df = checkpoint.load('age_pop')\n",
    "age_death_df = checkpoint.load('age_death')\n",
    "date_mean_df = checkpoint.load('date_mean')\n",
    "last_day_df = checkpoint.load('last_day')\n",
    "leading_indicator_df = checkpoint.load('leading_indicator')\n",
    "loc_df = checkpoint.load('location')\n",
    "\n",
    "submodel_dict = runner.submit_models(full_df, death_df, age_pop_df, age_death_df, date_mean_df, leading_indicator_df,\n",
    "                                     loc_df, r0_locs,\n",
    "                                     PEAK_FILE, OUTPUT_DIR, 'best',  # DATA_VERSION, \n",
    "                                     R0_FILE, CODE_DIR, verbose=False)\n",
    "\n",
    "checkpoint.write('submodel_dict', submodel_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile draws\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = checkpoint.load('full_data')\n",
    "age_pop_df = checkpoint.load('age_pop')\n",
    "threshold_dates = checkpoint.load('threshold_dates')\n",
    "submodel_dict = checkpoint.load('submodel_dict')\n",
    "loc_df = checkpoint.load('location')\n",
    "\n",
    "obs_df = full_df[full_df.location_id.isin(loc_df.location_id)]\n",
    "\n",
    "draw_dfs, past_draw_dfs, models_used, days, ensemble_draws_dfs = runner.compile_draws(loc_df,\n",
    "                                                                                      submodel_dict,\n",
    "                                                                                      obs_df,\n",
    "                                                                                      threshold_dates,\n",
    "                                                                                      age_pop_df)\n",
    "\n",
    "if 'location' not in models_used:\n",
    "    raise ValueError('No location-specific draws used, must be using wrong tag')\n",
    "draw_df = pd.concat(draw_dfs)\n",
    "model_type_df = pd.DataFrame({'location': loc_df['Location'].unique().tolist(),\n",
    "                              'model_used': models_used})\n",
    "\n",
    "# write\n",
    "draw_df.to_csv(f'{OUTPUT_DIR}/euro_data.csv', index=False)\n",
    "model_type_df.to_csv(f'{OUTPUT_DIR}/models_used.csv', index=False)\n",
    "ensemble_plot_path = runner.make_and_save_draw_plots(OUTPUT_DIR, loc_df,\n",
    "                                                     ensemble_draws_dfs, days, models_used, age_pop_df)\n",
    "print(ensemble_plot_path)\n",
    "checkpoint.write('draw_data', draw_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## combine with previous predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "avg_df = runner.average_draws(raw_draw_path, yesterday_draw_path, before_yesterday_draw_path)\n",
    "avg_df.to_csv(average_draw_path, index=False)\n",
    "compare_average_plot_path = runner.make_and_save_compare_average_plots(OUTPUT_DIR,\n",
    "                                                                       raw_draw_path,\n",
    "                                                                       average_draw_path,\n",
    "                                                                       yesterday_draw_path,\n",
    "                                                                       before_yesterday_draw_path,\n",
    "                                                                       'Not United States of America')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "compare_to_previous_plot_path = runner.make_and_save_compare_to_previous_plots(OUTPUT_DIR,\n",
    "                                                                               raw_draw_path,\n",
    "                                                                               yesterday_draw_path,\n",
    "                                                                               \"Not US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "viz_dir = runner.send_plots_to_diagnostics(DATESTAMP_LABEL,\n",
    "                                           f'{OUTPUT_DIR}/ensemble_plot.pdf',\n",
    "                                           #compare_average_plot_path,\n",
    "                                           compare_to_previous_plot_path)\n",
    "print(viz_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store deaths with smoothed past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.smooth_data(OUTPUT_DIR, raw_draw_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store point estimates, and peaks derived from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_df = checkpoint.load('location')\n",
    "submodel_dict = checkpoint.load('submodel_dict')\n",
    "draw_df = checkpoint.load('draw_data')\n",
    "age_pop_df = checkpoint.load('age_pop')\n",
    "\n",
    "runner.save_points_and_peaks(loc_df, submodel_dict, draw_df, age_pop_df, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
