{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "from db_queries import get_location_metadata\n",
    "import pandas as pd\n",
    "\n",
    "from covid_model_deaths import runner\n",
    "from covid_model_deaths.deaths_io import InputsContext, MEASURES, Checkpoint\n",
    "from covid_model_deaths.globals import COLUMNS\n",
    "\n",
    "pd.options.display.max_rows = 99\n",
    "pd.options.display.max_columns = 99\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "RUN_TYPE = 'prod'\n",
    "DATA_VERSION = '2020_05_01.08'\n",
    "DATESTAMP_LABEL = '2020_05_01_US_newmod'\n",
    "\n",
    "PEAK_FILE = '/ihme/covid-19/deaths/mobility_inputs/2020_04_20/peak_locs_april20_.csv'\n",
    "PEAK_DURATION_FILE = None\n",
    "R0_FILE = None\n",
    "LOCATION_SET_VERSION = 655\n",
    "r0_locs = []\n",
    "\n",
    "CODE_DIR = os.path.abspath('../src/covid_model_deaths')\n",
    "OUTPUT_DIR = f'/ihme/covid-19/deaths/{RUN_TYPE}/{DATESTAMP_LABEL}'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)\n",
    "inputs = InputsContext(f'/ihme/covid-19/model-inputs/{DATA_VERSION}')\n",
    "checkpoint = Checkpoint(OUTPUT_DIR)\n",
    "\n",
    "print(f'Writing to {OUTPUT_DIR}')\n",
    "print(CODE_DIR)\n",
    "print(checkpoint)\n",
    "\n",
    "raw_draw_path = f'{OUTPUT_DIR}/state_data.csv'\n",
    "average_draw_path = f'{OUTPUT_DIR}/past_avg_state_data.csv'\n",
    "yesterday_draw_path = '/ihme/covid-19/deaths/prod/2020_04_29_US/state_data.csv'\n",
    "before_yesterday_draw_path = '/ihme/covid-19/deaths/prod/2020_04_28_US/state_data.csv'\n",
    "\n",
    "\n",
    "def filter_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Remove bad or problematic data locations and dates.\"\"\"\n",
    "    # dropping data from May 1 for Mississippi for Lazio and Mississippi\n",
    "    mississippi_lazio = data['location_id'].isin([547, 35506])\n",
    "    mississippi_lazio_spike = mississippi_lazio & (data['Date'] == pd.Timestamp('2020-05-01'))\n",
    "    data = data.loc[~mississippi_lazio_spike].reset_index(drop=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_locations(location_set_version_id):\n",
    "    loc_df = get_location_metadata(location_set_id=111,\n",
    "                                   location_set_version_id=location_set_version_id)\n",
    "    most_detailed = loc_df['most_detailed'] == 1\n",
    "    us = loc_df['path_to_top_parent'].str.startswith('102,')\n",
    "    keep_columns = ['location_id', 'location_ascii_name', 'parent_id', 'level', 'most_detailed']\n",
    "\n",
    "    us_df = loc_df.loc[most_detailed & us, keep_columns]\n",
    "    us_df = us_df.rename(columns={'location_ascii_name': 'Location'})\n",
    "\n",
    "    # Add parents\n",
    "    loc_df = loc_df[['location_id', 'location_ascii_name']]\n",
    "    loc_df = loc_df.rename(columns={'location_id':'parent_id',\n",
    "                                    'location_ascii_name':'Country/Region'})\n",
    "\n",
    "    us_df = us_df.merge(loc_df)\n",
    "    us_df = us_df.loc[:, ['location_id', 'Location', 'Country/Region', 'level']]\n",
    "    return us_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read full (unrestricted) set from snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_df = get_locations(LOCATION_SET_VERSION)\n",
    "input_full_df = filter_data(inputs.load(MEASURES.full_data))\n",
    "input_death_df = filter_data(inputs.load(MEASURES.deaths))\n",
    "input_age_pop_df = inputs.load(MEASURES.age_pop)\n",
    "input_age_death_df = inputs.load(MEASURES.age_death)\n",
    "\n",
    "# Save pops for Bobby.\n",
    "inputs.load(MEASURES.us_pops).to_csv(f'{OUTPUT_DIR}/pops.csv', index=False)\n",
    "\n",
    "checkpoint.write('location', loc_df)\n",
    "checkpoint.write('full_data', input_full_df)\n",
    "checkpoint.write('deaths', input_death_df)\n",
    "checkpoint.write('age_pop', input_age_pop_df)\n",
    "checkpoint.write('age_death', input_age_death_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine back-casted death rates with cases for abie (using model dataset, i.e. admin1 and below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "full_df = checkpoint.load('full_data')\n",
    "death_df = checkpoint.load('deaths')\n",
    "age_pop_df = checkpoint.load('age_pop')\n",
    "age_death_df = checkpoint.load('age_death')\n",
    "\n",
    "backcast_location_ids = runner.get_backcast_location_ids(full_df)\n",
    "cases_and_backcast_deaths_df = runner.make_cases_and_backcast_deaths(full_df, death_df,\n",
    "                                                                     age_pop_df, age_death_df,\n",
    "                                                                     backcast_location_ids)\n",
    "\n",
    "cases_and_backcast_deaths_df.to_csv(f'{OUTPUT_DIR}/backcast_for_case_to_death.csv', index=False)\n",
    "checkpoint.write('cases_and_backcast_deaths', cases_and_backcast_deaths_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute death thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cases_and_backcast_deaths_df = checkpoint.load('cases_and_backcast_deaths')\n",
    "loc_df = checkpoint.load('location')\n",
    "threshold_dates = runner.impute_death_threshold(cases_and_backcast_deaths_df,\n",
    "                                                loc_df)\n",
    "threshold_dates.to_csv(f'{OUTPUT_DIR}/threshold_dates.csv', index=False)\n",
    "checkpoint.write('threshold_dates', threshold_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make last day data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = checkpoint.load('full_data')\n",
    "threshold_dates = checkpoint.load('threshold_dates')\n",
    "\n",
    "date_mean_df = runner.make_date_mean_df(threshold_dates)\n",
    "last_day_df = runner.make_last_day_df(full_df,date_mean_df)\n",
    "last_day_df.to_csv(f'{OUTPUT_DIR}/last_day.csv', index=False)\n",
    "\n",
    "checkpoint.write('date_mean', date_mean_df)\n",
    "checkpoint.write('last_day', last_day_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get leading indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = checkpoint.load('full_data')\n",
    "loc_df = checkpoint.load('location')\n",
    "\n",
    "dcr_df, dhr_df, leading_indicator_df = runner.make_leading_indicator(\n",
    "    full_df.loc[full_df[COLUMNS.location_id].isin(loc_df[COLUMNS.location_id].to_list())]\n",
    ")\n",
    "dcr_df.to_csv(f'{OUTPUT_DIR}/lagged_death_to_case_ratios.csv', index=False)\n",
    "dhr_df.to_csv(f'{OUTPUT_DIR}/lagged_death_to_hosp_ratios.csv', index=False)\n",
    "leading_indicator_df.to_csv(f'{OUTPUT_DIR}/leading_indicator.csv', index=False)\n",
    "leading_indicator_df = leading_indicator_df[[COLUMNS.location_id, COLUMNS.date, COLUMNS.ln_age_death_rate]]\n",
    "leading_indicator_df = leading_indicator_df.loc[~leading_indicator_df[COLUMNS.ln_age_death_rate].isnull()]\n",
    "\n",
    "checkpoint.write('leading_indicator', leading_indicator_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = checkpoint.load('full_data')\n",
    "death_df = checkpoint.load('deaths')\n",
    "age_pop_df = checkpoint.load('age_pop')\n",
    "age_death_df = checkpoint.load('age_death')\n",
    "date_mean_df = checkpoint.load('date_mean')\n",
    "last_day_df = checkpoint.load('last_day')\n",
    "leading_indicator_df = checkpoint.load('leading_indicator')\n",
    "loc_df = checkpoint.load('location')\n",
    "\n",
    "submodel_dict = runner.submit_models(full_df, death_df, age_pop_df, age_death_df, date_mean_df, leading_indicator_df,\n",
    "                                     loc_df, r0_locs,\n",
    "                                     PEAK_FILE, OUTPUT_DIR, 'best',  # DATA_VERSION, \n",
    "                                     R0_FILE, CODE_DIR, verbose=False)\n",
    "\n",
    "checkpoint.write('submodel_dict', submodel_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = checkpoint.load('full_data')\n",
    "age_pop_df = checkpoint.load('age_pop')\n",
    "threshold_dates = checkpoint.load('threshold_dates')\n",
    "submodel_dict = checkpoint.load('submodel_dict')\n",
    "loc_df = checkpoint.load('location')\n",
    "\n",
    "obs_df = full_df[full_df.location_id.isin(loc_df.location_id)]\n",
    "\n",
    "draw_dfs, past_draw_dfs, models_used, days, ensemble_draws_dfs = runner.compile_draws(loc_df,\n",
    "                                                                                      submodel_dict,\n",
    "                                                                                      obs_df,\n",
    "                                                                                      threshold_dates,\n",
    "                                                                                      age_pop_df)\n",
    "\n",
    "if 'location' not in models_used:\n",
    "    raise ValueError('No location-specific draws used, must be using wrong tag')\n",
    "draw_df = pd.concat(draw_dfs)\n",
    "model_type_df = pd.DataFrame({'location': loc_df['Location'].tolist(),\n",
    "                              'model_used': models_used})\n",
    "\n",
    "# write\n",
    "draw_df.to_csv(f'{OUTPUT_DIR}/state_data.csv', index=False)\n",
    "model_type_df.to_csv(f'{OUTPUT_DIR}/state_models_used.csv', index=False)\n",
    "ensemble_plot_path = runner.make_and_save_draw_plots(OUTPUT_DIR, loc_df,\n",
    "                                                     ensemble_draws_dfs, days, models_used, age_pop_df)\n",
    "print(ensemble_plot_path)\n",
    "checkpoint.write('draw_data', draw_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## total US deaths in this run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_df = checkpoint.load('draw_data')\n",
    "\n",
    "runner.display_total_deaths(draw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine with previous predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df = runner.average_draws(raw_draw_path, yesterday_draw_path, before_yesterday_draw_path)\n",
    "avg_df.to_csv(average_draw_path, index=False)\n",
    "compare_average_plot_path = runner.make_and_save_compare_average_plots(OUTPUT_DIR,\n",
    "                                                                       raw_draw_path,\n",
    "                                                                       average_draw_path,\n",
    "                                                                       yesterday_draw_path,\n",
    "                                                                       before_yesterday_draw_path,\n",
    "                                                                       'United States of America')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_to_previous_plot_path = runner.make_and_save_compare_to_previous_plots(OUTPUT_DIR,\n",
    "                                                                               raw_draw_path,\n",
    "                                                                               yesterday_draw_path,\n",
    "                                                                               label='United States')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_dir = runner.send_plots_to_diagnostics(DATESTAMP_LABEL,\n",
    "                                           f'{OUTPUT_DIR}/ensemble_plot.pdf',\n",
    "                                           compare_average_plot_path,\n",
    "                                           compare_to_previous_plot_path)\n",
    "print(viz_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store deaths with smoothed past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.smooth_data(OUTPUT_DIR, raw_draw_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store point estimates, and peaks derived from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_df = checkpoint.load('location')\n",
    "submodel_dict = checkpoint.load('submodel_dict')\n",
    "draw_df = checkpoint.load('draw_data')\n",
    "age_pop_df = checkpoint.load('age_pop')\n",
    "\n",
    "pop_df = age_pop_df.groupby('location_id', as_index=False)['population'].sum()\n",
    "\n",
    "def get_peak(location_id):\n",
    "    submodel_dirs = submodel_dict[location_id]['submodel_dirs']\n",
    "    dfs = []\n",
    "    if os.path.exists(f'{submodel_dirs[0]}/{location_id}/point_estimate.csv'):\n",
    "        for submodel_dir in submodel_dirs:\n",
    "            df = pd.read_csv(f'{submodel_dir}/{location_id}/point_estimate.csv')\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            dfs.append(df.sort_values('Date'))\n",
    "        df = pd.concat(dfs).reset_index(drop=True)\n",
    "        #full = True\n",
    "    else:\n",
    "        raise ValueError(f'Point estimate not found for {location_id}.')\n",
    "        # df = draw_df.loc[draw_df['location_id'] == location_id].copy()\n",
    "        # df = df.rename(index=str, columns={'date':'Date'})\n",
    "        # df = df.merge(pop_df)\n",
    "        # df['Age-standardized death rate'] = df[[f'draw_{d}' for d in range(1000)]].mean(axis=1) / df['population']\n",
    "        # df = df.sort_values('Date').reset_index(drop=True)\n",
    "        # df['Age-standardized death rate'][1:] = df['Age-standardized death rate'].values[1:] - df['Age-standardized death rate'].values[:-1]\n",
    "        # df = df.loc[~df['observed']]\n",
    "        # df = df[['location_id', 'Date', 'Age-standardized death rate']]\n",
    "        # full = False\n",
    "    df = df.groupby('Date', as_index=False)['Age-standardized death rate'].mean()\n",
    "    peak_df = df.sort_values('Date').reset_index(drop=True)\n",
    "    #if full:\n",
    "    peak_df = peak_df[15:]\n",
    "    peak_df = peak_df.sort_values('Age-standardized death rate', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    peak_date = peak_df['Date'][0]\n",
    "    df['peak_date'] = False\n",
    "    df.loc[df['Date'] == peak_date, 'peak_date'] = True\n",
    "    df['location_id'] = location_id\n",
    "\n",
    "    return df\n",
    "\n",
    "pred_df = pd.concat([get_peak(location_id) for location_id in loc_df['location_id'].to_list()])\n",
    "pred_df = pred_df.rename(index=str, columns={'Age-standardized death rate':'Daily death rate'})\n",
    "peak_dates_df = pred_df.loc[pred_df['peak_date']]\n",
    "\n",
    "pred_df = pred_df[['location_id', 'Date', 'Daily death rate']].reset_index(drop=True)\n",
    "pred_df.to_csv(f'{OUTPUT_DIR}/point_estimates.csv', index=False)\n",
    "peak_dates_df = peak_dates_df[['location_id', 'Date', 'Daily death rate']].reset_index(drop=True)\n",
    "peak_dates_df = peak_dates_df.rename(index=str, columns={'Date':'peak_date'})\n",
    "peak_dates_df.to_csv(f'{OUTPUT_DIR}/peak_dates.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
