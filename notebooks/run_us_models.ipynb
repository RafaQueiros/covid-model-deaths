{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "from db_queries import get_location_metadata\n",
    "import pandas as pd\n",
    "\n",
    "from covid_model_deaths import runner\n",
    "from covid_model_deaths.deaths_io import InputsContext, MEASURES, Checkpoint\n",
    "from covid_model_deaths.globals import COLUMNS\n",
    "\n",
    "pd.options.display.max_rows = 99\n",
    "pd.options.display.max_columns = 99\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "RUN_TYPE = 'dev'\n",
    "MODEL_INPUTS_VERSION = 'best'\n",
    "SNAPSHOT_VERSION = 'best'\n",
    "DATESTAMP_LABEL = '2020_05_05_US_obs_smooth'\n",
    "\n",
    "PEAK_FILE = '/ihme/covid-19/deaths/mobility_inputs/2020_04_20/peak_locs_april20_.csv'\n",
    "PEAK_DURATION_FILE = None\n",
    "R0_FILE = None\n",
    "LOCATION_SET_VERSION = 660\n",
    "r0_locs = []\n",
    "\n",
    "CODE_DIR = os.path.abspath('../src/covid_model_deaths')\n",
    "OUTPUT_DIR = f'/ihme/covid-19/deaths/{RUN_TYPE}/{DATESTAMP_LABEL}'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)\n",
    "inputs = InputsContext(f'/ihme/covid-19/model-inputs/{MODEL_INPUTS_VERSION}')\n",
    "checkpoint = Checkpoint(OUTPUT_DIR)\n",
    "\n",
    "print(f'Writing to {OUTPUT_DIR}')\n",
    "print(CODE_DIR)\n",
    "print(checkpoint)\n",
    "\n",
    "smooth_draw_path = f'{OUTPUT_DIR}/smoothed_state_data.csv'\n",
    "raw_draw_path = f'{OUTPUT_DIR}/state_data.csv'\n",
    "average_draw_path = f'{OUTPUT_DIR}/past_avg_smoothed_state_data.csv'\n",
    "yesterday_draw_path = '/ihme/covid-19/deaths/prod/2020_05_04_US/smoothed_state_data.csv'\n",
    "before_yesterday_draw_path = '/ihme/covid-19/deaths/prod/2020_05_03_US/smoothed_state_data.csv'\n",
    "\n",
    "\n",
    "def filter_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Remove bad or problematic data locations and dates.\"\"\"\n",
    "    # dropping data from May 1 for Mississippi for Lazio and Mississippi\n",
    "    mississippi_lazio = data['location_id'].isin([547, 35506])\n",
    "    mississippi_lazio_spike = mississippi_lazio & (data['Date'] == pd.Timestamp('2020-05-01'))\n",
    "    data = data.loc[~mississippi_lazio_spike].reset_index(drop=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_locations(location_set_version_id):\n",
    "    loc_df = get_location_metadata(location_set_id=111,\n",
    "                                   location_set_version_id=location_set_version_id)\n",
    "    most_detailed = loc_df['most_detailed'] == 1\n",
    "    us = loc_df['path_to_top_parent'].str.startswith('102,')\n",
    "    keep_columns = ['location_id', 'location_ascii_name', 'path_to_top_parent', 'level', 'most_detailed']\n",
    "\n",
    "    us_df = loc_df.loc[most_detailed & us, keep_columns]\n",
    "    us_df = us_df.rename(columns={'location_ascii_name': 'Location'})\n",
    "\n",
    "    # Add parents\n",
    "    loc_df = loc_df[['location_id', 'location_ascii_name']]\n",
    "    loc_df = loc_df.rename(columns={'location_id':'parent_id',\n",
    "                                    'location_ascii_name':'Country/Region'})\n",
    "    \n",
    "    us_df['parent_id'] = us_df['path_to_top_parent'].apply(lambda x: int(x.split(',')[0]))\n",
    "    us_df = us_df.merge(loc_df)\n",
    "    us_df = us_df.loc[:, ['location_id', 'Location', 'Country/Region', 'level']]\n",
    "    return us_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read full (unrestricted) set from snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_df = get_locations(LOCATION_SET_VERSION)\n",
    "input_full_df = filter_data(inputs.load(MEASURES.full_data))\n",
    "input_death_df = filter_data(inputs.load(MEASURES.deaths))\n",
    "input_age_pop_df = inputs.load(MEASURES.age_pop)\n",
    "input_age_death_df = inputs.load(MEASURES.age_death)\n",
    "smoothed_case_df, smoothed_death_df = runner.get_smoothed(input_full_df)\n",
    "\n",
    "# Save pops for Bobby.\n",
    "inputs.load(MEASURES.us_pops).to_csv(f'{OUTPUT_DIR}/pops.csv', index=False)\n",
    "\n",
    "checkpoint.write('location', loc_df)\n",
    "checkpoint.write('full_data', input_full_df)\n",
    "checkpoint.write('deaths', input_death_df)\n",
    "checkpoint.write('smoothed_cases', smoothed_case_df)\n",
    "checkpoint.write('smoothed_deaths', smoothed_death_df)\n",
    "checkpoint.write('age_pop', input_age_pop_df)\n",
    "checkpoint.write('age_death', input_age_death_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine back-casted death rates with cases for abie (using model dataset, i.e. admin1 and below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "full_df = checkpoint.load('full_data')\n",
    "death_df = checkpoint.load('deaths')\n",
    "age_pop_df = checkpoint.load('age_pop')\n",
    "age_death_df = checkpoint.load('age_death')\n",
    "\n",
    "backcast_location_ids = runner.get_backcast_location_ids(full_df)\n",
    "cases_and_backcast_deaths_df = runner.make_cases_and_backcast_deaths(death_df,\n",
    "                                                                     age_pop_df, age_death_df,\n",
    "                                                                     backcast_location_ids)\n",
    "\n",
    "cases_and_backcast_deaths_df.to_csv(f'{OUTPUT_DIR}/backcast_for_case_to_death.csv', index=False)\n",
    "checkpoint.write('cases_and_backcast_deaths', cases_and_backcast_deaths_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute death thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cases_and_backcast_deaths_df = checkpoint.load('cases_and_backcast_deaths')\n",
    "loc_df = checkpoint.load('location')\n",
    "threshold_dates = runner.impute_death_threshold(cases_and_backcast_deaths_df,\n",
    "                                                loc_df)\n",
    "threshold_dates.to_csv(f'{OUTPUT_DIR}/threshold_dates.csv', index=False)\n",
    "checkpoint.write('threshold_dates', threshold_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make last day data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_death_df = checkpoint.load('smoothed_deaths')\n",
    "threshold_dates = checkpoint.load('threshold_dates')\n",
    "\n",
    "date_mean_df = runner.make_date_mean_df(threshold_dates)\n",
    "last_day_df = runner.make_last_day_df(smoothed_death_df,date_mean_df)\n",
    "last_day_df.to_csv(f'{OUTPUT_DIR}/last_day.csv', index=False)\n",
    "\n",
    "checkpoint.write('date_mean', date_mean_df)\n",
    "checkpoint.write('last_day', last_day_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get leading indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = checkpoint.load('full_data')\n",
    "loc_df = checkpoint.load('location')\n",
    "\n",
    "dcr_df, dhr_df, leading_indicator_df = runner.make_leading_indicator(\n",
    "    full_df.loc[full_df[COLUMNS.location_id].isin(loc_df[COLUMNS.location_id].to_list())],\n",
    "    SNAPSHOT_VERSION\n",
    ")\n",
    "dcr_df.to_csv(f'{OUTPUT_DIR}/lagged_death_to_case_ratios.csv', index=False)\n",
    "dhr_df.to_csv(f'{OUTPUT_DIR}/lagged_death_to_hosp_ratios.csv', index=False)\n",
    "leading_indicator_df.to_csv(f'{OUTPUT_DIR}/leading_indicator.csv', index=False)\n",
    "leading_indicator_df = leading_indicator_df[[COLUMNS.location_id, COLUMNS.date, COLUMNS.ln_age_death_rate]]\n",
    "leading_indicator_df = leading_indicator_df.loc[~leading_indicator_df[COLUMNS.ln_age_death_rate].isnull()]\n",
    "\n",
    "checkpoint.write('leading_indicator', leading_indicator_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = checkpoint.load('full_data')\n",
    "death_df = checkpoint.load('deaths')\n",
    "age_pop_df = checkpoint.load('age_pop')\n",
    "age_death_df = checkpoint.load('age_death')\n",
    "date_mean_df = checkpoint.load('date_mean')\n",
    "last_day_df = checkpoint.load('last_day')\n",
    "leading_indicator_df = checkpoint.load('leading_indicator')\n",
    "loc_df = checkpoint.load('location')\n",
    "\n",
    "submodel_dict = runner.submit_models(full_df, death_df, age_pop_df, age_death_df, date_mean_df, leading_indicator_df,\n",
    "                                     loc_df, r0_locs,\n",
    "                                     PEAK_FILE, OUTPUT_DIR, \n",
    "                                     SNAPSHOT_VERSION, MODEL_INPUTS_VERSION, \n",
    "                                     R0_FILE, CODE_DIR, verbose=False)\n",
    "\n",
    "checkpoint.write('submodel_dict', submodel_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_death_df = checkpoint.load('smoothed_deaths')\n",
    "age_pop_df = checkpoint.load('age_pop')\n",
    "threshold_dates = checkpoint.load('threshold_dates')\n",
    "submodel_dict = checkpoint.load('submodel_dict')\n",
    "loc_df = checkpoint.load('location')\n",
    "\n",
    "# obs_df = full_df[full_df.location_id.isin(loc_df.location_id)]\n",
    "obs_df = smoothed_death_df[smoothed_death_df.location_id.isin(loc_df.location_id)]\n",
    "\n",
    "draw_dfs, past_draw_dfs, models_used, days, ensemble_draws_dfs = runner.compile_draws(loc_df,\n",
    "                                                                                      submodel_dict,\n",
    "                                                                                      obs_df,\n",
    "                                                                                      threshold_dates,\n",
    "                                                                                      age_pop_df)\n",
    "\n",
    "if 'location' not in models_used:\n",
    "    raise ValueError('No location-specific draws used, must be using wrong tag')\n",
    "draw_df = pd.concat(draw_dfs)\n",
    "model_type_df = pd.DataFrame({'location': loc_df['Location'].tolist(),\n",
    "                              'model_used': models_used})\n",
    "\n",
    "# write\n",
    "draw_df.to_csv(smooth_draw_path, index=False)\n",
    "model_type_df.to_csv(f'{OUTPUT_DIR}/state_models_used.csv', index=False)\n",
    "ensemble_plot_path = runner.make_and_save_draw_plots(OUTPUT_DIR, loc_df,\n",
    "                                                     ensemble_draws_dfs, days, models_used, age_pop_df)\n",
    "print(ensemble_plot_path)\n",
    "checkpoint.write('draw_data', draw_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## total US deaths in this run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_df = checkpoint.load('draw_data')\n",
    "\n",
    "runner.display_total_deaths(draw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store deaths with true past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = checkpoint.load('full_data')\n",
    "loc_df = checkpoint.load('location')\n",
    "\n",
    "raw_df['Location'] = raw_df['Province/State']\n",
    "raw_df = raw_df.loc[raw_df['location_id'].isin(loc_df['location_id'].to_list())]\n",
    "raw_df.loc[raw_df['Location'].isnull(), 'Location'] = raw_df['Country/Region']\n",
    "runner.swap_observed(OUTPUT_DIR, smooth_draw_path, raw_draw_path, raw_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine with previous predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df = runner.average_draws(smooth_draw_path, yesterday_draw_path, before_yesterday_draw_path, past_avg_window=10)\n",
    "avg_df.to_csv(average_draw_path, index=False)\n",
    "compare_average_plot_path = runner.make_and_save_compare_average_plots(OUTPUT_DIR,\n",
    "                                                                       smooth_draw_path,\n",
    "                                                                       average_draw_path,\n",
    "                                                                       yesterday_draw_path,\n",
    "                                                                       before_yesterday_draw_path,\n",
    "                                                                       'United States of America')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_to_previous_plot_path = runner.make_and_save_compare_to_previous_plots(OUTPUT_DIR,\n",
    "                                                                               smooth_draw_path,\n",
    "                                                                               yesterday_draw_path,\n",
    "                                                                               label='United States')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_dir = runner.send_plots_to_diagnostics(DATESTAMP_LABEL,\n",
    "                                           f'{OUTPUT_DIR}/ensemble_plot.pdf',\n",
    "                                           compare_average_plot_path,\n",
    "                                           compare_to_previous_plot_path)\n",
    "print(viz_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store point estimates, and peaks derived from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_df = checkpoint.load('location')\n",
    "submodel_dict = checkpoint.load('submodel_dict')\n",
    "draw_df = checkpoint.load('draw_data')\n",
    "age_pop_df = checkpoint.load('age_pop')\n",
    "\n",
    "runner.save_points_and_peaks(loc_df, submodel_dict, draw_df, age_pop_df, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
